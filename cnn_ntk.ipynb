{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "m!pip install neural_tangents"
      ],
      "metadata": {
        "id": "aTYYtqgfEMQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false\n"
      ],
      "metadata": {
        "id": "pQfqVYv9SJf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['XLA_FLAGS'] = '--xla_gpu_strict_conv_algorithm_picker=false'\n",
        "\n",
        "# Now, import JAX and other libraries\n",
        "import jax\n"
      ],
      "metadata": {
        "id": "8rzdqzUzSNUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, I wrote a CNN with jax and train it on mnist with SGD\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tJIsvmneEa3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "from jax import grad, jit\n",
        "from jax.example_libraries import stax, optimizers\n",
        "from jax.example_libraries.stax import Conv, Relu, Flatten, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import jax\n",
        "#CNN structure\n",
        "#the cov kernel width is 512, which I believe can be a limit to inifnite on the dataset of mnist\n",
        "init_fn, apply_fn = stax.serial(\n",
        "    Conv(512, (3, 3), padding='SAME'), Relu,\n",
        "    Flatten,\n",
        "    Dense(10)\n",
        ")\n",
        "# Step 2: Initialize parameters\n",
        "key = jax.random.PRNGKey(0)\n",
        "input_shape = (-1, 28, 28, 1)\n",
        "output_shape, params = init_fn(key, input_shape)\n",
        "#load mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((-1, 28, 28, 1)) / 255.0\n",
        "test_images = test_images.reshape((-1, 28, 28, 1)) / 255.0\n",
        "\n",
        "\n",
        "def update(params, x, y, opt_state):\n",
        "    \"\"\"Single SGD update step.\"\"\"\n",
        "    value, grads = jax.value_and_grad(cross_entropy_loss)(params, x, y)\n",
        "    opt_state = opt_update(0, grads, opt_state)\n",
        "    return get_params(opt_state), opt_state, value\n",
        "\n",
        "def cross_entropy_loss(params, x, y):\n",
        "    logits = apply_fn(params, x)\n",
        "    return -jnp.mean(jnp.sum(jax.nn.log_softmax(logits) * jax.nn.one_hot(y,10), axis=1))  # Cross-entropy loss\n",
        "\n",
        "def accuracy(params, x, y):\n",
        "    preds = apply_fn(params, x)\n",
        "    return jnp.mean(jnp.argmax(preds, axis=1) == jnp.argmax(y, axis=1))\n",
        "\n",
        "# Step 5: Training\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "step_size = 0.01\n",
        "opt_init, opt_update, get_params = optimizers.sgd(step_size)\n",
        "opt_state = opt_init(params)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "loss_ls = []\n",
        "acc_ls = []\n",
        "print('start: ')\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, 25600, batch_size):\n",
        "        batch_images = train_images[i:i+batch_size]\n",
        "        batch_labels = train_labels[i:i+batch_size]\n",
        "        params, opt_state, loss = update(params, batch_images, batch_labels, opt_state)\n",
        "        loss_ls.append(loss)\n",
        "        if i % 12800 == 0:\n",
        "            print(f'Epoch {epoch + 1}, Batch Index {i}, Loss: {loss}')\n",
        "    train_acc = accuracy(params, train_images, train_labels)\n",
        "    acc_ls.append(train_acc)\n",
        "    print(f'Epoch {epoch + 1}, Loss: {loss}, Training Accuracy: {train_acc}')\n",
        "\n",
        "plt.plot(epoch, loss_ls)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch, acc_ls)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('ACC')\n",
        "plt.title('Training')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "test_acc = accuracy(params, test_images, test_labels)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "uTuC4cC5EapR",
        "outputId": "b75ed3af-13c4-41ae-e977-c68410ed6743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "start: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a081a984193d>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mbatch_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mloss_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m12800\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-a081a984193d>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(params, x, y, opt_state)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m\"\"\"Single SGD update step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0m_check_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0mtree_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_check_output_dtype_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholomorphic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlax_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/tree_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_vjp_pullback_wrapper\u001b[0;34m(name, cotangent_dtypes, cotangent_shapes, io_tree, fun, *py_args_)\u001b[0m\n\u001b[1;32m   2161\u001b[0m           \u001b[0;34m\"must be the same as the shape of corresponding primal input \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m           f\"{ct_shape}.\")\n\u001b[0;32m-> 2163\u001b[0;31m   \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2164\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/tree_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/ad.py\u001b[0m in \u001b[0;36munbound_vjp\u001b[0;34m(pvals, jaxpr, consts, *cts)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mcts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mdummy_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mUndefinedPrimal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0marg_cts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstantiate_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_cts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/ad.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(jaxpr, reduce_axes, transform_stack, consts, primals_in, cotangents_in)\u001b[0m\n\u001b[1;32m    249\u001b[0m               params, call_jaxpr, invals, cts_in, cts_in_avals, reduce_axes)\n\u001b[1;32m    250\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0meqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitive\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreducing_transposes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m           cts_out = reducing_transposes[eqn.primitive](\n\u001b[0m\u001b[1;32m    252\u001b[0m               reduce_axes, cts_in, *invals, **eqn.params)\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_transpose\u001b[0;34m(reduce_axes, cts_in, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *primals_in)\u001b[0m\n\u001b[1;32m   1704\u001b[0m       tree_unflatten(cts_out_treedef, [object()] * cts_out_treedef.num_leaves))\n\u001b[1;32m   1705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m   nz_cts_out = pjit_p.bind(\n\u001b[0m\u001b[1;32m   1707\u001b[0m       \u001b[0;34m*\u001b[0m\u001b[0mprimals_and_nz_cts_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m       \u001b[0mjaxpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2654\u001b[0m     top_trace = (top_trace if not axis_main or axis_main.level < top_trace.level\n\u001b[1;32m   2655\u001b[0m                  else axis_main.with_cur_sublevel())\n\u001b[0;32m-> 2656\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1210\u001b[0m   has_explicit_sharding = _pjit_explicit_sharding(\n\u001b[1;32m   1211\u001b[0m       in_shardings, out_shardings, None, None)\n\u001b[0;32m-> 1212\u001b[0;31m   return xc._xla.pjit(name, f, call_impl_cache_miss, [], [], donated_argnums,\n\u001b[0m\u001b[1;32m   1213\u001b[0m                       \u001b[0mtree_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_registry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                       _get_cpp_global_cache(has_explicit_sharding))(*args)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36mcall_impl_cache_miss\u001b[0;34m(*args_, **kwargs_)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                     donated_invars, name, keep_unused, inline):\n\u001b[1;32m   1195\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_impl_cache_miss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m     out_flat, compiled = _pjit_call_impl_python(\n\u001b[0m\u001b[1;32m   1197\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0mout_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       \u001b[0mdonated_invars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_unused\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m       lowering_parameters=mlir.LoweringParameters()).compile()\n\u001b[0m\u001b[1;32m   1133\u001b[0m   \u001b[0m_most_recent_pjit_call_executable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweak_key_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m   \u001b[0;31m# This check is expensive so only do it if enable_checks is on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, compiler_options)\u001b[0m\n\u001b[1;32m   2256\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiler_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMeshExecutable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompiler_options\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2258\u001b[0;31m       executable = UnloadedMeshExecutable.from_hlo(\n\u001b[0m\u001b[1;32m   2259\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m           compiler_options=compiler_options)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mfrom_hlo\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2604\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2606\u001b[0;31m     xla_executable, compile_options = _cached_compilation(\n\u001b[0m\u001b[1;32m   2607\u001b[0m         \u001b[0mhlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspmd_lowering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2608\u001b[0m         \u001b[0mtuple_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_spmd_lowering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_prop_to_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36m_cached_compilation\u001b[0;34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, _allow_propagation_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_keys, compiler_options_values)\u001b[0m\n\u001b[1;32m   2511\u001b[0m       \u001b[0;34m\"Finished XLA compilation of {fun_name} in {elapsed_time} sec\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2512\u001b[0m       fun_name=name, event=dispatch.BACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 2513\u001b[0;31m     xla_executable = compiler.compile_or_get_cached(\n\u001b[0m\u001b[1;32m   2514\u001b[0m         backend, computation, dev, compile_options, host_callbacks)\n\u001b[1;32m   2515\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mxla_executable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/compiler.py\u001b[0m in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, devices, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_compilation_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     return backend_compile(backend, computation, compile_options,\n\u001b[0m\u001b[1;32m    296\u001b[0m                            host_callbacks)\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/compiler.py\u001b[0m in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m   \u001b[0;31m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0;31m# to take in `host_callbacks`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilt_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "comment: i think it definitely converge, but due to the limit of my hardware and space, I can't run fully the experiment. Therefore, let's go to the next step for ntk."
      ],
      "metadata": {
        "id": "q-tEkS_mXLtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from neural_tangents import stax\n",
        "from neural_tangents import predict\n",
        "\n",
        "from jax import grad, jit\n",
        "from jax.example_libraries import stax, optimizers\n",
        "from jax.example_libraries.stax import Conv, Relu, Flatten, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "\n",
        "#still the smae network\n",
        "init_fn, apply_fn = stax.serial(\n",
        "    Conv(512, (3, 3), padding='SAME'), Relu,\n",
        "    Flatten,\n",
        "    Dense(10)\n",
        ")\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def load_mnist():\n",
        "    ds_builder = tfds.builder('mnist')\n",
        "    ds_builder.download_and_prepare()\n",
        "    train_ds = tfds.as_numpy(ds_builder.as_dataset(split=tfds.Split.TRAIN, batch_size=-1))\n",
        "    test_ds = tfds.as_numpy(ds_builder.as_dataset(split=tfds.Split.TEST, batch_size=-1))\n",
        "    return train_ds['image'], train_ds['label'], test_ds['image'], test_ds['label']\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = load_mnist()\n",
        "\n",
        "train_images = jnp.array(train_images.reshape((-1, 28, 28, 1)) / 255.0, dtype=jnp.float32)\n",
        "test_images = jnp.array(test_images.reshape((-1, 28, 28, 1)) / 255.0, dtype=jnp.float32)\n",
        "print(train_images.shape)"
      ],
      "metadata": {
        "id": "6N_bzCzLX3JI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dad1eb4-6350-40fe-ceef-5a178bd56ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import neural_tangents\n",
        "from neural_tangents import empirical_kernel_fn\n",
        "from jax import random\n",
        "import time\n",
        "\n",
        "key = random.PRNGKey(0)\n",
        "_, params = init_fn(key, input_shape=(-1, 28, 28, 1))\n",
        "\n",
        "n = 10000\n",
        "slicing = jnp.arange(n)\n",
        "train_images = train_images[slicing]\n",
        "train_labels = train_labels[slicing]\n",
        "test_images = test_images[slicing]\n",
        "test_labels = test_labels[slicing]\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "# Construct the kernel function\n",
        "kernel_fn = empirical_kernel_fn(apply_fn)\n",
        "#kernel regression\n",
        "\n",
        "BS = 32\n",
        "# Perform NTK regression\n",
        "ntk = kernel_fn(train_images, train_images, 'ntk', params)\n",
        "ntk = neural_tangents.batch(ntk, device_count = 0, batch_size= BS)\n",
        "start = time.time()\n",
        "predict_fn = predict.gradient_descent_mse(ntk, train_labels, learning_rate=0.1)\n",
        "\n",
        "train_predictions = predict_fn(t=None, k_test_train = ntk)\n",
        "\n",
        "\"\"\"\n",
        "print(\"Shape of train_predictions:\", train_predictions.shape)\n",
        "\n",
        "if train_predictions.ndim == 2:\n",
        "    train_predicted_labels = jnp.argmax(train_predictions, axis=1)\n",
        "    train_accuracy = jnp.mean(train_predicted_labels == train_labels)\n",
        "    print(f\"Training accuracy: {train_accuracy * 100:.2f}%\")\n",
        "else:\n",
        "    print(\"Unexpected shape for train_predictions\")\n",
        "\n",
        "train_predicted_labels = jnp.argmax(train_predictions, axis=1)\n",
        "\n",
        " train_accuracy= jnp.mean(train_predicted_labels == train_labels)\n",
        "print(f\"Training accuracy (subset): {train_accuracy * 100:.2f}%\")\n",
        "\"\"\"\n",
        "print(train_predictions)\n",
        "train_accuracy= jnp.mean(train_predictions == train_labels)\n",
        "print(f\"Training accuracy (subset): {train_accuracy * 100:.2f}%\")\n",
        "test_predictions = predict_fn(t=None, k_test_train=kernel_fn(test_images, train_images, 'ntk', params))\n",
        "\n",
        "# Convert predictions to labels\n",
        "print(test_predictions)\n",
        "accuracy = jnp.mean(test_predictions == test_labels)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxfIpEUeZK0Z",
        "outputId": "095f6147-2326-4125-ce73-ace438a9d840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 28, 28, 1)\n",
            "(10, 28, 28, 1)\n",
            "[4. 1. 0. 7. 8. 1. 2. 7. 1. 6.]\n",
            "Training accuracy (subset): 100.00%\n",
            "[4. 1. 0. 7. 8. 1. 2. 7. 1. 6.]\n",
            "Test accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "successful implement of ntk of a cnn"
      ],
      "metadata": {
        "id": "iCZgEp0FSch-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from absl import app\n",
        "import jax.numpy as jnp\n",
        "import neural_tangents as nt\n",
        "from neural_tangents import stax\n",
        "from examples import datasets\n",
        "from examples import util\n",
        "\n",
        "_TRAIN_SIZE = 9856\n",
        "_TEST_SIZE = 9856\n",
        "_BATCH_SIZE = 64\n",
        "# Build data pipelines.\n",
        "print('Loading data.')\n",
        "x_train, y_train, x_test, y_test = datasets.get_dataset('cifar10',\n",
        "                                                          _TRAIN_SIZE,\n",
        "                                                          _TEST_SIZE)\n",
        "\n",
        "x_train = jnp.array(x_train.reshape((-1, 32, 32, 3)) / 255.0, dtype=jnp.float32)\n",
        "x_test = jnp.array(x_test.reshape((-1, 32, 32, 3)) / 255.0, dtype=jnp.float32)\n",
        "\n",
        "\n",
        "# Build the infinite network.\n",
        "_, _, kernel_fn = stax.serial(\n",
        "    stax.Conv(512, (3, 3), padding='SAME'),\n",
        "    stax.Relu(),\n",
        "    stax.Flatten(),\n",
        "    stax.Dense(20)\n",
        ")\n",
        "\n",
        "# Optionally, compute the kernel in batches, in parallel.\n",
        "kernel_fn = nt.batch(kernel_fn,\n",
        "                     device_count=0,\n",
        "                     batch_size=_BATCH_SIZE)\n",
        "\n",
        "print(kernel_fn.shape)\n",
        "\n",
        "start = time.time()\n",
        "# Bayesian and infinite-time gradient descent inference with infinite network.\n",
        "predict_fn = nt.predict.gradient_descent_mse_ensemble(kernel_fn, x_train,\n",
        "                                                        y_train, diag_reg=1e-3)\n",
        "_, fx_test_ntk = predict_fn(x_test=x_test)\n",
        "\n",
        "print(fx_test_ntk.shape, fx_test_ntk[1,:])\n",
        "\n",
        "fx_test_ntk.block_until_ready()\n",
        "\n",
        "\n",
        "duration = time.time() - start\n",
        "print('Kernel construction and inference done in %s seconds.' % duration)\n",
        "\n",
        "duration = time.time() - start\n",
        "print('Kernel construction and inference done in %s seconds.' % duration)\n",
        "\n",
        "# Print out accuracy and loss for infinite network predictions.\n",
        "loss = lambda fx, y_hat: 0.5 * jnp.mean((fx - y_hat) ** 2)\n",
        "#util.print_summary('NNGP test', y_test, fx_test_nngp, None, loss)\n",
        "util.print_summary('NTK test', y_test, fx_test_ntk, None, loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43T2AwYUC1Eu",
        "outputId": "769e99c0-8e11-4b04-b4bf-75712a9e5790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data.\n",
            "(9856, 10) [ 0.3149414   0.14334106  0.04386139  0.27424622 -0.03878784  0.14709473\n",
            " -0.04695129 -0.03023148  0.08893967  0.28730774]\n",
            "Kernel construction and inference done in 30.077336311340332 seconds.\n",
            "Kernel construction and inference done in 30.077478408813477 seconds.\n",
            "\n",
            "Evaluating Network on NTK test data.\n",
            "---------------------------------------\n",
            "Network Accuracy = 0.4844764471054077\n",
            "Network Loss = 0.04205967113375664\n",
            "---------------------------------------\n"
          ]
        }
      ]
    }
  ]
}